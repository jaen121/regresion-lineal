---
title: "Tarea 3"
author: "Jairo Enrique Alba"
date: "28/3/2023"
output: pdf_document
---
Con base en los datos de ofertas de vivienda descargadas del portal finca raiz para
apartamento de estrato 4 con área construida menor a 200 (vivienda4.RDS) la
inmobiliaria A&C requiere el apoyo en la construcción de un modelo que lo oriente
sobre los precios de inmuebles, por lo tanto se realiza un análisis descriptivo correspondiente al precio y al área construida tambien se analiza el tipo de vivienda y la zona donde se encuentra ubicada.

También se establecerá un modelo lineal para predecir el precio del inmueble teniendo en cuenta el área construida, es decir el precio sera la variable respuesta y el área construida es la variable predictora, en otras palabras $y = \beta_{0} + \beta_{1}x + \epsilon$.




## Análisis Exploratorio de Variables

+  **Análisis Exploratorio de la Variable Precio de  la Vivienda**

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(readxl)
library(data.table)
library(paqueteMET)
library(writexl)#libreria para guardar el archivo como excel.

data <- readRDS("Datos/vivienda4.RDS")

# Realice un análisis exploratorio de las variables precio de vivienda (millones de pesos COP)
# y área de la vivienda (metros cuadrados) - incluir gráficos e indicadores apropiados interpretados.

# Medidas de centralidad para el precio
promedio <- mean(data$preciom,na.rm = T)
mediana <- median(data$preciom,na.rm = T)
# moda (con datos agrupados en intervalos usando el caso de igual longitud de intervalos)

# Medidas de variabilidad para el precio
coef_apertura <- max(data$preciom, na.rm = T)/min(data$preciom,na.rm = T)
varianza <- var(data$preciom, na.rm = T)
desv_estandar <- sd(data$preciom, na.rm = T)
CV <- round(100*desv_estandar/promedio,2)

# Coeficiente de asimertria y curtosis para el precio
CA <- mean((data$preciom - promedio)^3)/(mean((data$preciom - promedio)^2))^(3/2)
CC <- mean((data$preciom - promedio)^4)/(mean((data$preciom - promedio)^2))^(2) - 3



# Medidas de posicion para el precio
Q1 <- quantile(data$preciom, probs = 0.25, type = 6)
Q2 <- quantile(data$preciom, probs = 0.50, type = 6)
Q3 <- quantile(data$preciom, probs = 0.75, type = 6)


# Tabla resumen para el precio
tb_resumen <- data.frame(
  Minimo = min(data$preciom, na.rm = T),
  Q1 = Q1,
  Q2 = Q2,
  Promedio = promedio,
  Mediana = mediana,
  Q3 = Q3,
  Maximo = max(data$preciom, na.rm = T),
  Coef_apertura = coef_apertura,
  varianza = varianza,
  Desv.Estandar = desv_estandar,
  Coef.Variacion = CV,
  Coef.Asimetria = CA,
  Coef.Curtosis = CC
)
print(paste(" El analisis exploratorio de datos nos arrojo los siguientes resultados:"))

tb_resumen
saveRDS(tb_resumen, "Resultados/tb_resumen.rds")
#write_xlsx(tb_resumen,"Resultados/AED_precio.xlsx")

```

| Estadístico       | Valor   | 
|-------------------|-------------|
| Mínimo            | 78    | 
| Cuartil 1        | 160       | 
| Cuartil 2 = Mediana | 210 | 
| Promedio         | 255.3746 | 
| Cuartil 3        | 265 |
| Máximo         | 760 |
| Varianza         | 7376.274 |
| Desviación estándar         | 85.8853 |
| Coeficiente de Variación        | 38.11% |
| Coeficiente de asimetría         | 1.4908 |
| Curtosis         | 3.5731 |

De las medidas encontradas evidenciamos un precio mínimo y maximo de las casas de 78 y 760 respectivamente con un promedio de precio de 255.38, además se observa que el 25%(427) de las casa presentaron un valor entre 78 y 160, mientras que el 50%(853) de las mismas tenian un precio entre 78 y 210, finalmente el 75%(1280) de las casas presentaron valores entre  78 y 265. Con lo descrito anteriormente se puede inferir que los precios de las casas se encuentran sesgados de manera positiva y lo podemos validar con el coeficiente de asimetría 1.49, por otro lado la curtosis nos informa que la distribución es leptocúrtica 3,5731. Con respecto a la dispersión de los precios se tienen unos valores de 7376.274 y 85.89 para la varianza y desvición estándar.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Histograma para el precio
hist(data$preciom, freq = FALSE,main = "Distribución del Precio de las Viviendas",
     xlab = "Precio de la vivienda", ylab = "Conteo", col = "green")


lines(density(data$preciom),col="red",lwd=2)

curve(dnorm(x,mean=mean(data$preciom),sd=sd(data$preciom)), from=0,to=1000, 
      add=TRUE, col="blue", lwd=2)

legend("topleft",col=c("blue","red"),legend =c("Densidad normal estimada","Estimador de núcleo de la densidad"),lwd=2, bty = "n")


# Diagrama de caja para el precio
boxplot(data$preciom, main = "Distribución del Precio de las Viviendas",
        xlab = "Precio de la vivienda", ylab = "Conteo", col = "green", horizontal = TRUE)

# Datos atípicos para el precio

bi <- Q1 - 1.5*(Q3 - Q1)
print(paste(" El límite inferior es:"))
bi 

bi1 <- max(bi,78)
# bigote inferior es 78
print(paste(" El bigote inferior es:"))
bi1


bs <- Q3 + 1.5*(Q3 - Q1)
print(paste(" El límite superior es:"))
bs

bs2<- min(bs,760)
#bigote superior  es 422.5
print(paste(" El bigote superior es:"))
bs2
```
Se observa que existen datos atípicos superiores, es decir aquellos precios  superiores a 422.5, datos atípicos inferiores no se encontraron.

A continuación analizaremos la normalidad de la variable precio del inmueble:

```{r}
library(normtest) ###REALIZA 5 PRUEBAS DE NORMALIDAD###
library(nortest) ###REALIZA 10 PRUEBAS DE NORMALIDAD###
library(moments) ###REALIZA 1 PRUEBA DE NORMALIDAD###
lillie.test(data$preciom)
shapiro.test(data$preciom)
```

Las gráficas anteriores muestran una distribución sesgada positivamente, con la presencia de datos atípicos superiores los cuales los podemos evidenciar en el diagrama de cajas, dichos datos son aquellos precios de las casas superiores a 422.5, mediante la prueba de normalidad de Kolmogorov-Smirnov nos arrojo un p-valor de $2.2(10^{-16})$ confirmando que la distribución de los datos no es normal. 


+  **Análisis Exploratorio de la Variable área construida**

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Medidas de centralidad para el área construida
promedioa <- mean(data$areaconst,na.rm = T)
medianaa <- median(data$areaconst,na.rm = T)
# moda (con datos agrupados en intervalos usando el caso de igual longitud de intervalos)

# Medidas de variabilidad para el área construida
coef_aperturaa <- max(data$areaconst, na.rm = T)/min(data$areaconst,na.rm = T)
varianzaa <- var(data$areaconst, na.rm = T)
desv_estandara <- sd(data$areaconst, na.rm = T)
CVa <- round(100*desv_estandara/promedioa,2)

# Coeficiente de asimertria y curtosis para el área construida
CAa <- mean((data$areaconst - promedioa)^3)/(mean((data$areaconst - promedioa)^2))^(3/2)
CCa <- mean((data$areaconst - promedioa)^4)/(mean((data$areaconst - promedioa)^2))^(2) - 3



# Medidas de posicion para el área construida
Q1a <- quantile(data$areaconst, probs = 0.25, type = 6)
Q2a <- quantile(data$areaconst, probs = 0.50, type = 6)
Q3a <- quantile(data$areaconst, probs = 0.75, type = 6)


# Tabla resumen para el área construida
tb_resumen <- data.frame(
  Minimoa = min(data$areaconst, na.rm = T),
  Q1a = Q1a,
  Q2a = Q2a,
  Promedioa = promedioa,
  Medianaa = medianaa,
  Q3a = Q3a,
  Maximoa = max(data$areaconst, na.rm = T),
  Coef_aperturaa = coef_aperturaa,
  varianzaa = varianzaa,
  Desv.Estandara = desv_estandara,
  Coef.Variaciona = CVa,
  Coef.Asimetriaa = CAa,
  Coef.Curtosisa = CCa
)
print(paste(" El analisis exploratorio de datos nos arrojo los siguientes resultados:"))
tb_resumen
#saveRDS(tb_resumen, "Resultados/tb_resumenareaconst.rds")
#write_xlsx(tb_resumen,"Resultados/AED_areaconst.xlsx")
```


| Estadístico       | Valor   | 
|-------------------|-------------|
| Mínimo            | 40    | 
| Cuartil 1        | 60       | 
| Cuartil 2 = Mediana | 75 | 
| Promedio         | 87.6295 | 
| Cuartil 3        | 98 |
| Máximo         | 200 |
| Varianza         | 1321.069 |
| Desviación estándar         | 36.3465 |
| Coeficiente de Variación        | 41.48% |
| Coeficiente de asimetría         | 1.533 |
| Curtosis         | 1,683 |

De las medidas encontradas evidenciamos un área de construcción mínima y maxima de las casas de 40 y 60 respectivamente con un promedio de área de 87.6295, además se observa que el 25%(427) de las casa presentaron un área entre 40  y 60, mientras que el 50%(853) de las mismas tenian un área entre 40 y 75, finalmente el 75%(1280) de las casas presentaron valores entre  40 y 98. Con lo descrito anteriormente se puede inferir que las áreas de las casas se encuentran sesgados de manera positiva y lo podemos validar con el coeficiente de asimetría 1.533, por otro lado la curtosis nos informa que la distribución es leptocúrtica 1,683. Con respecto a la dispersión de los precios se tienen unos valores de 1321.069 y 36.3465 para la varianza y desvición estándar.


```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Histograma para el área construida
hist(data$areaconst, freq = FALSE,main = "Distribución del área construida",
     xlab = "Área construida", ylab = "Conteo", col = "green")


lines(density(data$areaconst),col="red",lwd=2)

curve(dnorm(x,mean=mean(data$areaconst),sd=sd(data$areaconst)), from=0,to=1000, 
      add=TRUE, col="blue", lwd=2)

legend("topleft",col=c("blue","red"),legend =c("Densidad normal estimada","Estimador de núcleo de la densidad"),lwd=2, bty = "n")


# Diagrama de caja para el área construida
boxplot(data$areaconst, main = "Distribución del Precio de las Viviendas",
        xlab = "Precio dela vivienda", ylab = "Conteo", col = "green", horizontal = TRUE)

# Datos atípicos para el área construida

bia <- Q1a - 1.5*(Q3a - Q1a)
print(paste(" El límite inferior es:"))
bia
bi1a <- max(bia,40)
print(paste(" El bigote inferior es:"))
bi1a
# bigote inferior es 40

bsa <- Q3a + 1.5*(Q3a - Q1a)
print(paste(" El límite superior es:"))
bsa
bs1a <- min(bsa,200)
print(paste(" El bigote superior es:"))
bs1a
# bigote superior es 155
```
Se observa que existen datos atípicos superiores, es decir aquellos superiore  superiores a 155, datos atípicos inferiores no se encontraron.

A continuación analizaremos la normalidad de la variable área construida del inmueble:
```{r}
library(normtest) ###REALIZA 5 PRUEBAS DE NORMALIDAD###
library(nortest) ###REALIZA 10 PRUEBAS DE NORMALIDAD###
library(moments) ###REALIZA 1 PRUEBA DE NORMALIDAD###
lillie.test(data$areaconst)
shapiro.test(data$areaconst)
```
Las gráficas anteriores muestran una distribución sesgada positivamente, con la presencia de datos atípicos superiores los cuales los podemos evidenciar en el diagrama de cajas, dichos datos son aquellos precios de las casas superiores a 155, mediante la prueba de normalidad de Kolmogorov-Smirnov nos arrojo un p-valor de $2.2(10^{-16})$ confirmando que la distribución de los datos no es normal. 





## Análisis por Zona y tipo de vivienda
```{r, echo=FALSE, warning=FALSE, message=FALSE, include = FALSE}
#================================= #include = FALSE para que no muestre la salida
library(dplyr)
horas_agr1 <- data %>% 
  select(preciom, zona) #seleccionar solo precio y zona
  
str(horas_agr1)
#=========== para hacer el conteo por zonas
conteo_h <- horas_agr1 %>% 
  group_by(zona) %>% #agrupar por zonas
  summarise(n_i = n()) %>%  #sumarizar valores a una sola fila por grupo
  mutate(N_i = cumsum(n_i), f_i = n_i /sum(n_i), F_i = cumsum(f_i))#crear encabezado de la tabla
str(conteo_h)#imprimir tabla

saveRDS(conteo_h, "Resultados/conteo_h.rds")#guardar archivo en formato .RDS más facile de leer.

conteo_h5 <- conteo_h %>% # realizar el conteo del top de los 5 mejores.
  arrange(desc(n_i)) %>% 
  slice(1:5)

#library(esquisse)#libreria para crear gráficos
#esquisser()# crear el gráfico, importando datos.

library(ggplot2)

ggplot(horas_agr1) +
 aes(x = zona, y = preciom,  colour = zona) +
 geom_col() +
 scale_fill_gradient() +
 scale_color_hue(direction = 1) +
 labs(x = "Zonas") +
 theme_minimal()

#esquisser()

conteo_h2 <- data %>% 
  group_by(tipo) %>% #agrupar por zonas
  summarise(n_i = n()) %>%  #sumarizar valores a una sola fila por grupo
  mutate(N_i = cumsum(n_i), f_i = n_i /sum(n_i), F_i = cumsum(f_i))#crear encabezado de la tabla
str(conteo_h2)#imprimir tabla

saveRDS(conteo_h2, "Resultados/conteo_h.rds")#guardar archivo en formato .RDS más facile de leer.

conteo_h2 <- conteo_h2 %>% # realizar el conteo del top de los 5 mejores.
  arrange(desc(n_i)) %>% 
  slice(1:5)

library(ggplot2)

ggplot(data) +
 aes(x = tipo, y = preciom, colour = tipo) +
 geom_col(fill = "#112446") +
 scale_color_hue(direction = 1) +
 theme_minimal()
```
De los datos observados se evidencia que el 79% corresponde a la zona sur, 17% corresponde a la zona norte, el 4% zona oeste, el 0.5% zona centro y el 0.4%.

| Zona      | Frecuencia   | Porcentaje |
|-------------------|-------------|-------------|
| Sur            | 1344    | 79% |
| Norte        | 288      | 17% |
| Oeste | 60| 4% |
| Centro         | 8 |0.05 % |
| Oriente         | 6 |0.04 |

En cuanto al tipo de vivienda el 80% corresponde a apartamentos y 20% a casas.

| Tipo      | Frecuencia   | Porcentaje |
|-------------------|-------------|-------------|
| Apartamento            | 1363    | 80% |
| Casa        | 343     | 20% |

## Para un mejor modelo excluimos los datos atípicos

Para mejorar el modelo excluimos los datos atípicos

```{r}

# Datos sin datos atípicos

data1=subset(data, (data$preciom < 422.5  & data$areaconst < 155))

# pairs(data1) # para hacer gráficas cruzando las variables 
```

## Análisis Exploratorio Bivariado

### Nube de Puntos o gráfica de dispersión

A continuación elaboramos la gráfica de puntos o de dispersión para análizar de manera gráfica si existe algún tipo de correlación entre la variable área construida y el precio de la casa.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Gráfica de dispersión

library(ggplot2)

ggplot(data = data1, mapping = aes(x = areaconst, y = preciom)) +
  geom_point(color = "firebrick", size = 2) +
  labs(title = "Diagrama de dispersión", x = "Área Construida", y = "Precio") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

De la gráfica anterior podemos evidenciar una correlación lineal positiva (directa) entre las variables **área construida** como variable predictora y la variable **precio de la vivienda** como variable respuesta, es decir a mayor área construida mayor será el precio.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Analisis de la correlación

cor.test(x = data1$areaconst, y = data1$preciom, method = "pearson", digits = 3)
```


```{r, echo=FALSE, warning=FALSE, message=FALSE,include = FALSE}
#install.packages("GGally")
library(GGally)
ggpairs(data1, lower = list(continuous = "smooth"), diag = list(continuous = "bar"), axisLabels = "none")


```

De la salida anterior podemos concluir que:

+  Visualizando los gráficos de dispersión podemos observar que la variable areaconst (área construida) está  linealmente asociada con la variable respuesta preciom (precio de la vivienda), por lo que utilizaremos un modelo lineal.

+  El coeficiente de correlación de Pearson es  alta (r = 0.729557) y significativo (p-value = 2.2e-16). Ello indica una correlación entre ambas variables alta. Lo cual lo verificamos con el intervalo de confianza para dicho coeficiente (0.7053494,  0.7520650)

+  Por lo tanto tiene sentido generar el modelo de regresión lineal ya que se cumplen los primeros requisitos.


## Elaboración del modelo de regresión lineal simple

A continuación estableceremos un modelo lineal simple para predecir el precio de las casas teniendo en cuenta el área construida, de la forma 

\begin{center}
$y = \beta_{1}x + \beta_{0}  + \epsilon$
\end{center}

donde x será el área de la casa e y el precio.

Veamos, 

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Cálculo del modelo de resesión lineal simple

modelo.lineal <- lm(preciom ~ areaconst , data = data1)
# Información del modelo
summary(modelo.lineal)

```
\begin{center}
Resumen del modelo
\end{center}

El resumen del modelo presenta los errores estándar, el valor del estadístico $t$ y el correspondiente p-valor de los parámetros $\hat{\beta_{0}}$ y $\hat{\beta_{1}}$. El p-valor nos permite dterminar si los estimadores de los parámetros son significativamente distintos de cero, es decir que contribuyen al modelo. El parámetro $\hat{\beta_{1}}$ correspondiente a la pendiente suele ser el más util de estos modelos.

De los resultados obtenidos podemos concluir los siguiente:

+  Tanto el parámetro $\hat{\beta_{0}}$ correspondiente al corte con el eje y como $\hat{\beta_{1}}$ correspondiente a la pendiente son significativos, ya que los p-valores fueron $2.2(10^{-16})$

+  El coeficiente de determinación $R^{2}$ indica que el modelo es capaz de explicar el 53% de la variabilidad presente en la variable respuesta (precio) mediante la variable predictora (área construida).

+  El p-valor obtenido en el test $F$ es $2.2(10^{-16})$ el cual determina que es significativamente superior la varianza explicada por el modelo en comparación con la varianza total, por lo tanto se puede aceptar el modelo como útil y válido.

+  Ecuación del modelo estará determinada por: $Precio = 2.067(área\text{  }  construida) + 46.76 + \epsilon$, es decir por cada unidad que se incrementa en el área, el precio aumenta 2.067 unidades

## Intervalos de confianza para los parámetros del modelo

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Intervalo de confianza del modelo

confint(modelo.lineal)
```

Los intervalos de confianza para los parámetros $\hat{\beta_{0}}$ y $\hat{\beta_{1}}$son respectivamente (38.85, 54.68) y (1.97, 2.16), lo cual nos confirma la estimación que no incluyen el cero.

## Representación gráfica del modelo

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
ggplot(data = data1, mapping = aes(x = areaconst , y = preciom)) +
geom_point(color = "firebrick", size = 2) +
geom_smooth(method = "lm", se = TRUE, color = "black") +
labs(title = "Precio ~ Área Construida", x = "Área Construida", y = "Precio") +
theme_bw() + theme(plot.title = element_text(hjust = 0.5)) 
```

## Verificación de las  condiciones para aceptar el modelo

Para verificar los supuestos que debe cumplir los residuos para poder  aplicar la teoría de tal forma que el modelo sea válido y confiable, se debe tener en cuenta los siguiente:

+ Análisis de los residuos (distribución, variabilidad…)(plot(modelo) )

+ Test de hipótesis de Shapiro Wilk para el análisis de normalidad(shapiro.test(modelo$residuals))

+ Test de contraste de homocedasticidad Breusch-Pagan (bptest(modelo))

+ Detección de observaciones influyentes (influence.measures(modelo))

+ Visualización de observaciones influyentes (influencePlot(modelo))

+ Test de detección de outliers (outlierTest(modelo))

+ Cálculo de residuos estudentizados (rstudent(modelo))

### Normalidad de los residuos

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Contraste de hipótesis (normalidad de los residuos)
shapiro.test(modelo.lineal$residuals)

hist(modelo.lineal$residuals, freq = FALSE,main = "Residuos del modelo",
     xlab = "Residuos", ylab = "Conteo", col = "green")
boxplot(modelo.lineal$residuals, main = "Residuos del modelo",
        xlab = "Residuos", ylab = "Conteo", col = "green", horizontal = TRUE)
```

Observamos que los residuos para este modelo no se ditribuyen de manera normal ($p-valor = 4.558(10^{-15})$) también lo observamos a través del histograma y el diagrama de cajas.

### Homocedasticidad de los residuos

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Test de Breush-Pagan (homocedasticidad de los residuos)
library(lmtest)
bptest(modelo.lineal)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Análisis gráfico autocorrelación de los residuos
library(ggplot2)
ggplot(data = data1, aes(x = seq_along(modelo.lineal$residuals), 
                         y = modelo.lineal$residuals)) +
geom_point(aes(color = modelo.lineal$residuals)) +
scale_color_gradient2(low = "blue3", mid = "grey", high = "red") +
geom_line(size = 0.3) + 
labs(title = "Distribución de los residuos", x = "index", y = "residuo")+ 
geom_hline(yintercept = 0) + 
theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

La condición de homocedasticidad (supuesto de varianza constante)  parece no cumplirse ya que p-valor es  2.2e-16.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
#Valores ajustados versus residuos
#par(mfrow=c(1,2))
#plot(modelo.lineal)
```

En resumen, la normalidad de los residuos parece que no podemos aceptarla, y tampoco parecen seguir una clara tendencia según el orden de registro de las observaciones, tampoco  la condición de homocedasticidad  parece no cumplirse. 

Sin embargo al observar algunos  gráficos podríamos sospechar que algunas observacionesque pueden  estar influyendo al modelo. Para analizar en qué medida pueda estar influyendo esta u otras observaciones, se  **reajustará** el modelo excluyendo posibles observaciones sospechosas. 

Dependiendo de la finalidad del modelo, la exclusión de posibles outliers debe analizarse con detalles, ya que estas observaciones podrían ser errores de medida, pero también podrían representar casos interesantes.

También podrian utilizarse otros tipos de modelos tales como: lineal-logarítmico, logarítmico-lineal, logarítmico-logarítmico. 

Primero excluyamos los datos influyentes y ajustemos el modelo:

## Datos que estan influenciando en el modelo

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Residuos estudentizados
studentized_residual <- rstudent(modelo.lineal)
which(abs(studentized_residual) > 3)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE,include = FALSE}
library(car)
summary(influence.measures(model = modelo.lineal))
```

Valores con mayor influencia en el modelo son:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
influencePlot(model = modelo.lineal)

```
En este  análisis de los residuos estudentizados se logra  detectar  observaciones atípicas, la observaciones 199, 217,397, 585, 672, 935 parece estar influenciando en gran medida al modelo.

Procederemos a reajustar el modelo excluyendo dichas observaciones. Veamoslo en la siguiente gráfica:

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
ggplot(data = data1, mapping = aes(x = areaconst , y = preciom)) +
geom_point(color = "grey50", size = 2) +
#recta de regresión con todas las observaciones
geom_smooth(method = "lm", se = FALSE, color = "black") +
#se resalta el valor excluido
geom_point(data = data1[c(199, 217, 397, 585, 672, 935), ], color = "red", size = 2) +
#se añade la nueva recta de regresión
geom_smooth(data = data1[c(-199, -217, -397, -585, -672, -935), ], method="lm", se =FALSE,color = "blue") +
labs(x = "Diámetro", y = "Volumen") +
theme_bw() + theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

Realizamos nuevamente el modelo lineal excluyendo aquellos valores que estaban influenciando en el modelo.

### Modelo 2: excluyendo los valores más influyentes

```{r, echo=FALSE, warning=FALSE, message=FALSE}
modelo.lineal2 <- lm(preciom ~ areaconst, data = data1[c(-199, -217, -397, -585, -672, -935),])
summary(modelo.lineal2)
shapiro.test(modelo.lineal2$residuals)
```
### Modelo 3:  excluyendo todos los valores influyentes
```{r, echo=FALSE, warning=FALSE, message=FALSE}
modelo.lineal3 <- lm(preciom ~ areaconst, data = data1[c(-135,-148,-184, -199,  -217,-330,-334,-392, -397, -452,-573, -627, -629, -672,-679,-687, -727, -848, -887,-915,-1451,-1509,-1510,-1512),])
summary(modelo.lineal3)
shapiro.test(modelo.lineal3$residuals)
```

### Modelo 4:  Modelo Lineal -logarítmico
```{r, echo=FALSE, warning=FALSE, message=FALSE}
modelo.lineal4 <- lm(preciom ~ log(areaconst), data = data1)
summary(modelo.lineal4)
shapiro.test(modelo.lineal4$residuals)
```
### Modelo 5:  Modelo Logaritmo -lineal
```{r, echo=FALSE, warning=FALSE, message=FALSE}
modelo.lineal5 <- lm(log(preciom) ~ areaconst, data = data1)
summary(modelo.lineal5)
shapiro.test(modelo.lineal5$residuals)
```

### Modelo 6:  Modelo Logaritmo - Logaritmo
```{r, echo=FALSE, warning=FALSE, message=FALSE}
modelo.lineal6 <- lm(log(preciom) ~ log(areaconst), data = data1)
summary(modelo.lineal6)
shapiro.test(modelo.lineal6$residuals)
```
**Resumenes de los tistintos modelos construidos**




| Modelo       | $\hat{\beta_{0}}$   | $\hat{\beta_{1}}$   | $R^{2}$   |  p-normalidad residuos |Modelo  |
|-------------------|-------------|-------------|-------------|-------------|-------------|
|     Modelo 1       | 46.76    | 2.067 | 0.53 | $4.558(10^{-15})$| $y = 46.76 + 2.067 x$|
|     Modelo 2       | 44.22    | 2.099 | 0.55 | $3.175(10^{-13})$| $y = 44.22 +  2.099  x$|
|     Modelo 3       | 38.14    | 2.176 | 0.6 | $2.054(10^{-6})$| $y = 38.14 +  2.176  x$|
|     Modelo 4       | -579.44  | 182.29 | 0.57 | $5.066(10^{-15})$| $y = -579.44 +  182.29log(x)$|
|     Modelo 5       | 4.55    | 0.0095 | 0.52 | $8.142(10^{-6})$| $log(y) = 4.55 +  0.0095  x$|
|     Modelo 6       | 1.6244    | 0.849 | 0.58 | $2.376(10^{-7})$| $log(y) = 0.849 +  0.58log(x)$|

Del resumen anterior se evidencia que el mejor modelo es el 3, $R^{2}=0.6$, sin embargo los residuos no se comportan de manera normal, parece que la mejor opción es buscar más datos que afectan el modelo y excluirlos, para buscar la satisfacción de los supuestos del modelo. Sin embargo utilizaremos el modelo 6 para para predecir algunas observaciones.

## Uso del modelo 3  para predecir nuevas observaciones
```{r}
# Precio PROMEDIO que esperaríamos del precio de una casa de 110 metros de área construida.
predict(modelo.lineal3, data.frame(areaconst = 110), interval = "confidence")
```

```{r}
# Precio esperado  del precio de una casa de 110 metros de área construida
predict(modelo.lineal3, data.frame(areaconst = 110), interval = "prediction")
```

**Por lo tanto se espera que en promedio el precio de un inmueble de área de 110 sea de 277,45. Podemos afirmar con un 95% de confianza que el verdadero valor promedio se encuentra entre (273.96- 280.94), mientras que el intervalo de predicción para una solo inmueble de  área este entre (198.72 - 356.18) y su valor predicho es  277.45, por lo tanto  un precio de 200 millones parece una atractiva oferta, sin embargo se debe tener en cuenta el tipo de vivienda(apartamento o casa) y la zona donde se encuentra ubicado(sur, norte, oeste,centro u oriente)
y en la medida de lo posible establecer un modelo para la zona y el tipo de inmueble, además se debe pedir asesoría de expertos en el negocio.**

## Informe para los directivos.


La información encontrada de la matriz de datos correspondiente a los datos de ofertas de vivienda descargadas del portal Fincaraiz para inmuebles  de estrato 4 con área construida menor a 200$m^{2}$ se  evidenció un precio mínimo y maximo de los inmuebles  de 78 y 760 respectivamente con un promedio de precio de 255.38, además se observa que el 25%(427) de las casa presentaron un valor entre 78 y 160, mientras que el 50%(853) de las mismas tenian un precio entre 78 y 210, finalmente el 75%(1280) de las casas presentaron valores entre  78 y 265. Con lo descrito anteriormente se puede inferir que los precios de las casas se encuentran sesgados de manera positiva y lo podemos validar con el coeficiente de asimetría 1.49, por otro lado la curtosis nos informa que la distribución es leptocúrtica 3,5731. Con respecto a la dispersión de los precios se tienen unos valores de 7376.274 y 85.89 para la varianza y desvición estándar.

Con respecto al areá construida se obtuvo las siguientes medida: la construcción mínima y maxima de los inmuebles fueron  de 40 y 60 respectivamente con un promedio de área de 87.6295, además se observa que el 25%(427) de las casa presentaron un área entre 40  y 60, mientras que el 50%(853) de las mismas tenian un área entre 40 y 75, finalmente el 75%(1280) de las casas presentaron valores entre  40 y 98. Con lo descrito anteriormente se puede inferir que las áreas de las casas se encuentran sesgados de manera positiva y lo podemos validar con el coeficiente de asimetría 1.533, por otro lado la curtosis nos informa que la distribución es leptocúrtica 1,683. Con respecto a la dispersión de los precios se tienen unos valores de 1321.069 y 36.3465 para la varianza y desvición estándar.

Además  se evidencia que el 79% corresponde a la zona sur, 17% corresponde a la zona norte, el 4% zona oeste, el 0.5% zona centro y el 0.4%.

| Zona      | Frecuencia   | Porcentaje |
|-------------------|-------------|-------------|
| Sur            | 1344    | 79% |
| Norte        | 288      | 17% |
| Oeste | 60| 4% |
| Centro         | 8 |0.05 % |
| Oriente         | 6 |0.04 |

En cuanto al tipo de vivienda el 80% corresponde a apartamentos y 20% a casas.

| Tipo      | Frecuencia   | Porcentaje |
|-------------------|-------------|-------------|
| Apartamento            | 1363    | 80% |
| Casa        | 343     | 20% |

También de la construcción de un  modelo lineal para predecir el precio del inmuble a partir del área construida se obtuvo e evidenció que el mejor modelo es $y = 38.14 + 2.1755 x + \epsilon$, es decir $precio = 38.14 + 2.1755 (área\text{ } construida) + \epsilon$, dicho modelo es capaz de explicar el 60% ($R^{2}=0.6$) de la variabilidad presente en la variable respuesta (precio) mediante la variable predictora (área construida). Sin embargo los residuos no se comportan de manera normal, parece que la mejor opción es buscar más datos que afectan el modelo y excluirlos, para buscar la satisfacción de los supuestos del modelo.

Para la utilización del modelo se recomienda tener en cuenta el tipo de inmueble y la ubicación del mismo
y en la medida de lo posible establecer un modelo particularizando las condiciones del inmueble (zona y tipo de inmueble), además se debe pedir asesoría de expertos en el negocio.